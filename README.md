# Task 5: Decision Trees & Random Forests â€” Heart Disease Prediction

## ðŸŽ¯ Objective
The goal of this task is to learn **tree-based models** for classification using the **Heart Disease Dataset** and compare the performance of **Decision Trees** vs **Random Forests**. We also explore **overfitting**, **tree depth control**, and **feature importance**.

---

## ðŸ“¦ Tools Used
- **Scikit-learn** â€” Model building & evaluation  
- **Pandas** â€” Data loading & preprocessing  
- **Graphviz** â€” Visualizing Decision Trees  
- **Matplotlib** â€” Plotting results  

Dataset: [Heart Disease Dataset (Kaggle)](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)

---

## ðŸ“‹ Steps Performed
1. **Load Dataset** from CSV  
2. **Train/Test Split** (80/20 split)  
3. **Train a Decision Tree Classifier** with default parameters  
4. **Visualize the tree** using Graphviz  
5. **Limit max depth** to prevent overfitting  
6. **Train a Random Forest Classifier** and compare results  
7. **Cross-validation** for stability check  
8. **Evaluate with precision, recall, and F1-score**  
9. **Interpret feature importances**  

---

## ðŸ“Š Model Results

| Model                              | Accuracy  | Precision (Class 0 / Class 1) | Recall (Class 0 / Class 1) | F1-score (Weighted) | Cross-validation Accuracy |
|------------------------------------|-----------|--------------------------------|----------------------------|---------------------|---------------------------|
| Decision Tree (default)            | **98.54%** | 0.97 / 1.00                    | 1.00 / 0.97                | 0.99                 | 1.0000                    |
| Decision Tree (Max Depth = 3)      | 78.05%    | -                              | -                          | -                   | -                         |
| Random Forest                      | **98.54%** | 0.97 / 1.00                    | 1.00 / 0.97                | 0.99                 | 0.9971                    |

---

## ðŸŒ³ Decision Tree Visualization (Graphviz)

A decision tree can be exported and visualized to show how splits are made at each node.  
Example code to visualize:  

```python
from sklearn.tree import export_graphviz
import graphviz

# Export tree to DOT format
dot_data = export_graphviz(
    dt_model,  
    out_file=None,  
    feature_names=X.columns,  
    class_names=['No Heart Disease', 'Heart Disease'],  
    filled=True,  
    rounded=True,  
    special_characters=True
)

# Render tree
graph = graphviz.Source(dot_data)
graph.render("decision_tree_visualization", format="png", cleanup=True)
graph

